{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jGEwily5OuPC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from torchinfo import summary\n",
        "from torchvision.transforms import v2 as T\n",
        "\n",
        "from utils import (\n",
        "    train,\n",
        "    model_calassification_report,\n",
        "    plot_taining\n",
        ")\n",
        "\n",
        "from typing import Literal, List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfnJ62DUHBVn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yY64Fi5tOgKq"
      },
      "outputs": [],
      "source": [
        "# Transforms base (sin augmentation) para validaciÃ³n\n",
        "img_transform = T.Compose([\n",
        "    T.ToImage(),\n",
        "    T.Resize((572, 572)),\n",
        "    T.ToDtype(torch.float32, scale=True)\n",
        "])\n",
        "\n",
        "mask_transform = T.Compose([\n",
        "    T.ToImage(),\n",
        "    T.Resize((572, 572)),\n",
        "    T.Grayscale(num_output_channels=1),\n",
        "    T.ToDtype(torch.float32, scale=False),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jOihWDSCPnWC"
      },
      "outputs": [],
      "source": [
        "# Creamos la clase que nos permita cargar test dataset\n",
        "class SegmentationTestDataset(Dataset):\n",
        "    def __init__(self, images_dir, img_transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.img_transform = img_transform\n",
        "\n",
        "        self.images = sorted(os.listdir(images_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.images[idx])\n",
        "\n",
        "        img  = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.img_transform:\n",
        "            img = self.img_transform(img)\n",
        "\n",
        "        return img, self.images[idx]  # retornamos tambiÃ©n el nombre del archivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gAetR4Q9aXWp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… DoubleConv definido\n"
          ]
        }
      ],
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    Bloque de doble convoluciÃ³n: [Conv â†’ BN â†’ ReLU] x2\n",
        "    \n",
        "    SegÃºn el paper U-Net: 2x (3x3 conv + ReLU)\n",
        "    AÃ±adimos Batch Normalization para estabilidad\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch: int, out_ch: int, use_bn: bool = True):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        \n",
        "        # Primera convoluciÃ³n\n",
        "        layers.append(nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=not use_bn))\n",
        "        if use_bn:\n",
        "            layers.append(nn.BatchNorm2d(out_ch))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        \n",
        "        # Segunda convoluciÃ³n\n",
        "        layers.append(nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1, bias=not use_bn))\n",
        "        if use_bn:\n",
        "            layers.append(nn.BatchNorm2d(out_ch))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        \n",
        "        self.block = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.block(x)\n",
        "\n",
        "print(\"âœ… DoubleConv definido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g9BrIn2Ta6bL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Down block definido\n"
          ]
        }
      ],
      "source": [
        "class Down(nn.Module):\n",
        "    \"\"\"\n",
        "    Downsampling block: MaxPool â†’ DoubleConv\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch: int, out_ch: int, use_bn: bool = True):\n",
        "        super().__init__()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv = DoubleConv(in_ch, out_ch, use_bn=use_bn)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "print(\"âœ… Down block definido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zniVfasLbDVs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Up block definido\n"
          ]
        }
      ],
      "source": [
        "class Up(nn.Module):\n",
        "    \"\"\"\n",
        "    Upsampling block: Up-conv â†’ Concat con skip â†’ DoubleConv\n",
        "    \n",
        "    Args:\n",
        "        in_ch: Canales de entrada (de la capa profunda)\n",
        "        out_ch: Canales de salida\n",
        "        bilinear: Si True usa interpolaciÃ³n bilinear, si False usa ConvTranspose2d\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch: int, out_ch: int, bilinear: bool = True, use_bn: bool = True):\n",
        "        super().__init__()\n",
        "        \n",
        "        if bilinear:\n",
        "            # Upsampling bilinear + conv 1x1 para reducir canales\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.reduce = nn.Conv2d(in_ch, in_ch // 2, kernel_size=1)\n",
        "        else:\n",
        "            # ConvTranspose2d (up-conv aprendida)\n",
        "            self.up = nn.ConvTranspose2d(in_ch, in_ch // 2, kernel_size=2, stride=2)\n",
        "            self.reduce = nn.Identity()\n",
        "        \n",
        "        # DoubleConv despuÃ©s de concatenar\n",
        "        # in_ch // 2 (de up) + out_ch (de skip connection)\n",
        "        self.conv = DoubleConv(in_ch // 2 + out_ch, out_ch, use_bn=use_bn)\n",
        "\n",
        "    @staticmethod\n",
        "    def _pad_to_match(x: torch.Tensor, ref: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Ajustar x para que coincida con el tamaÃ±o espacial de ref\"\"\"\n",
        "        diff_y = ref.size(2) - x.size(2)\n",
        "        diff_x = ref.size(3) - x.size(3)\n",
        "        if diff_x == 0 and diff_y == 0:\n",
        "            return x\n",
        "        # Padding: [left, right, top, bottom]\n",
        "        return F.pad(x, [diff_x // 2, diff_x - diff_x // 2, \n",
        "                        diff_y // 2, diff_y - diff_y // 2])\n",
        "\n",
        "    def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.up(x)\n",
        "        x = self.reduce(x)\n",
        "        x = self._pad_to_match(x, skip)\n",
        "        # Concatenar en dimensiÃ³n de canales\n",
        "        x = torch.cat([skip, x], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "print(\"âœ… Up block definido\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "REl749q9bOXJ"
      },
      "outputs": [],
      "source": [
        "class OutConv(nn.Module):\n",
        "  def __init__(self, in_ch: int, out_ch: int):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WE-ALFGRtuWX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Arquitectura U-Net completa definida\n"
          ]
        }
      ],
      "source": [
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Arquitectura U-Net completa\n",
        "    \n",
        "    Args:\n",
        "        in_channels: NÃºmero de canales de entrada (1 para grayscale, 3 para RGB)\n",
        "        num_classes: NÃºmero de canales de salida (1 para segmentaciÃ³n binaria)\n",
        "        base_ch: NÃºmero de filtros en el primer nivel (64 en paper original)\n",
        "        depth: NÃºmero de niveles de pooling (4 en paper original)\n",
        "        bilinear: Si True usa upsampling bilinear, si False usa ConvTranspose2d\n",
        "        use_bn: Si True usa Batch Normalization\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=1, num_classes=1, base_ch=64, depth=4, \n",
        "                 bilinear=False, use_bn=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Calcular canales en cada nivel: [64, 128, 256, 512, 1024]\n",
        "        chs = [base_ch * (2 ** i) for i in range(depth + 1)]\n",
        "        \n",
        "        # ========== ENCODER ==========\n",
        "        # Primer bloque (sin maxpool)\n",
        "        self.inc = DoubleConv(in_channels, chs[0], use_bn=use_bn)\n",
        "        \n",
        "        # Bloques descendentes con maxpool\n",
        "        self.downs = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            self.downs.append(Down(chs[i], chs[i + 1], use_bn=use_bn))\n",
        "        \n",
        "        # ========== DECODER ==========\n",
        "        self.ups = nn.ModuleList()\n",
        "        for i in reversed(range(depth)):\n",
        "            self.ups.append(Up(chs[i + 1], chs[i], bilinear=bilinear, use_bn=use_bn))\n",
        "        \n",
        "        # ConvoluciÃ³n de salida\n",
        "        self.outc = OutConv(chs[0], num_classes)\n",
        "        \n",
        "        # InicializaciÃ³n de pesos\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        \"\"\"InicializaciÃ³n Kaiming (He) para capas con ReLU\"\"\"\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # ========== ENCODER ==========\n",
        "        skips = []\n",
        "        \n",
        "        # Primer nivel\n",
        "        x = self.inc(x)\n",
        "        skips.append(x)\n",
        "        \n",
        "        # Descenso con skip connections\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skips.append(x)\n",
        "        \n",
        "        # ========== DECODER ==========\n",
        "        # El Ãºltimo skip es el bottleneck, lo usamos como punto de partida\n",
        "        x = skips.pop()\n",
        "        \n",
        "        # Ascenso con skip connections del encoder\n",
        "        for up in self.ups:\n",
        "            skip = skips.pop()\n",
        "            x = up(x, skip)\n",
        "        \n",
        "        # ConvoluciÃ³n de salida\n",
        "        return self.outc(x)\n",
        "\n",
        "print(\"âœ… Arquitectura U-Net completa definida\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Du-8iKUjdTpS"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "zul4Kg_rdVLN"
      },
      "outputs": [],
      "source": [
        "model = UNet(\n",
        "    in_channels=3,      \n",
        "    num_classes=1,      # SegmentaciÃ³n binaria\n",
        "    base_ch=64,         # Paper original\n",
        "    depth=4,            # 4 niveles de pooling\n",
        "    bilinear=True,     # Usar ConvTranspose2d\n",
        "    use_bn=True         # Batch Normalization\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\joaco\\AppData\\Local\\Temp\\ipykernel_26672\\34797639.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('unet_epoch_100.pth',map_location=torch.device('cpu')))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (inc): DoubleConv(\n",
              "    (block): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (downs): ModuleList(\n",
              "    (0): Down(\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Down(\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): Down(\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Down(\n",
              "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): Up(\n",
              "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "      (reduce): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): Up(\n",
              "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "      (reduce): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): Up(\n",
              "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "      (reduce): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): Up(\n",
              "      (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
              "      (reduce): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (conv): DoubleConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (outc): OutConv(\n",
              "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('unet_epoch_100.pth',map_location=torch.device('cpu')))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instanciamos el dataset y dataloader de test\n",
        "test_ds = SegmentationTestDataset(\n",
        "    \"test/images\",\n",
        "    img_transform=img_transform\n",
        ")\n",
        "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "TEST_IMAGES_DIR = \"test/images\"  # ajustÃ¡ si tu carpeta es distinta\n",
        "\n",
        "def resize_mask_to_original(pred_mask, img_name):\n",
        "    \"\"\"\n",
        "    pred_mask: mÃ¡scara [H, W] en 0/1 (572x572)\n",
        "    img_name: nombre del archivo en test/images\n",
        "    \"\"\"\n",
        "    # Abrimos la imagen original para conocer el tamaÃ±o real (p.ej. 800x800)\n",
        "    img_path = os.path.join(TEST_IMAGES_DIR, img_name)\n",
        "    with Image.open(img_path) as im:\n",
        "        w, h = im.size  # PIL da (width, height)\n",
        "\n",
        "    # Convertimos la mÃ¡scara a imagen 0-255\n",
        "    mask_img = Image.fromarray((pred_mask * 255).astype(np.uint8))\n",
        "\n",
        "    # Redimensionamos al tamaÃ±o original usando NEAREST (no inventa grises)\n",
        "    mask_img = mask_img.resize((w, h), resample=Image.NEAREST)\n",
        "\n",
        "    # Volvemos a numpy 0/1\n",
        "    mask_resized = (np.array(mask_img) > 0).astype(np.uint8)  # [h, w]\n",
        "    return mask_resized\n",
        "\n",
        "def rle_encode(mask):\n",
        "    \"\"\"\n",
        "    mask: array 2D (H, W) con 0/1\n",
        "    Devuelve string RLE en formato Kaggle, flatten(order='F')\n",
        "    \"\"\"\n",
        "    pixels = mask.flatten(order='F')  # columna a columna\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] = runs[1::2] - runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submission_4.csv guardado\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission = []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, img_names in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)  # [B, 1, 572, 572]\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > 0.5).float()\n",
        "\n",
        "        for i in range(images.size(0)):\n",
        "            img_name = img_names[i]\n",
        "            pred_mask_572 = preds[i, 0].cpu().numpy()  # [572, 572]\n",
        "\n",
        "            # 1) Reescalar al tamaÃ±o original (800x800)\n",
        "            pred_mask_orig = resize_mask_to_original(pred_mask_572, img_name)  # [H, W] original\n",
        "\n",
        "            # 2) RLE en formato Kaggle (orden Fortran)\n",
        "            rle_str = rle_encode(pred_mask_orig)\n",
        "\n",
        "            submission.append({\n",
        "                'id': img_name,      # ðŸ‘ˆ revisÃ¡ si Kaggle quiere \"xxx.png\" o solo \"xxx\"\n",
        "                'rle_mask': rle_str\n",
        "            })\n",
        "\n",
        "submission_df = pd.DataFrame(submission)\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "print(\"submission_4.csv guardado\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "iagenerativa",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

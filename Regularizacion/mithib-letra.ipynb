{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIT-BIH Arrhythmia\n",
    "\n",
    "En esta notebook, implementaremos técnicas de regularización, tales como early stopping y dropout, utilizando el [MIT-BIH Arrhythmia Database](https://physionet.org/content/mitdb/1.0.0). El objetivo principal es mejorar la generalización de nuestros modelos de aprendizaje profundo y prevenir el sobreajuste durante el entrenamiento.\n",
    "\n",
    "## Introducción\n",
    "\n",
    "### Objetivos\n",
    "\n",
    "1. **Implementar y entender las técnicas de regularización** más comunes en redes neuronales, incluyendo early stopping y dropout.\n",
    "2. **Entrenar modelos de clasificación** en PyTorch utilizando el MIT-BIH Arrhythmia Database.\n",
    "3. **Evaluar el impacto de las técnicas de regularización** en el rendimiento del modelo utilizando métricas adecuadas.\n",
    "\n",
    "### Contenido\n",
    "\n",
    "1. Configuración de bibliotecas y semillas para reproducibilidad.\n",
    "2. Carga y exploración del MIT-BIH Arrhythmia Database.\n",
    "3. Preparación de los datos y división en conjuntos de entrenamiento y prueba.\n",
    "4. Definición y entrenamiento de modelos de clasificación en PyTorch.\n",
    "5. Implementación de técnicas de regularización como dropout y early stopping.\n",
    "6. Evaluación y comparación del rendimiento de los modelos con y sin regularización.\n",
    "\n",
    "### Sobre el conjunto de datos\n",
    "\n",
    "El MIT-BIH Arrhythmia Database es un conjunto de datos ampliamente utilizado en la investigación de la arritmia cardíaca. Contiene registros de electrocardiogramas (ECG) de diferentes pacientes, con anotaciones detalladas sobre distintos tipos de arritmias. Este conjunto de datos nos permitirá entrenar modelos de clasificación capaces de identificar distintos tipos de arritmias a partir de los datos de ECG, haciendo énfasis en la importancia de la regularización para mejorar la precisión y generalización de los modelos.\n",
    "\n",
    "El modelo esta disponible en el siguiente [link](https://www.kaggle.com/shayanfazeli/heartbeat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "from utils import plot_taining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos la semilla para que los resultados sean reproducibles\n",
    "SEED = 34\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# definimos el dispositivo que vamos a usar\n",
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "elif torch.xpu.is_available():\n",
    "    DEVICE = \"xpu\"  # si no hay GPU, pero hay XPU, usamos XPU\n",
    "\n",
    "print(f\"Usando {DEVICE}\")\n",
    "\n",
    "NUM_WORKERS = 0 # Win y MacOS pueden tener problemas con múltiples workers\n",
    "if sys.platform == 'linux':\n",
    "    NUM_WORKERS = 4  # numero de workers para cargar los datos (depende de cada caso)\n",
    "\n",
    "print(f\"Usando {NUM_WORKERS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048  # tamaño del batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos + Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"data/mitbih_train.csv\"\n",
    "TEST_DATA_PATH = \"data/mitbih_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_DATA_PATH, header=None)\n",
    "df_test = pd.read_csv(TEST_DATA_PATH, header=None)\n",
    "\n",
    "# Concatenamos los datos de entrenamiento y test\n",
    "df = pd.concat([df_train, df_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ninputs = df.shape[1] - 1\n",
    "nclasses = df.iloc[:, -1].nunique()\n",
    "print(f\"Existen {nclasses} clases y {ninputs} características\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, :-1]  # Extraemos las características\n",
    "y_train = df_train.iloc[:, -1]  # Extraemos las etiquetas\n",
    "\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAMES = [\n",
    "    \"Normal beat\",\n",
    "    \"Supraventricular premature beat\",\n",
    "    \"Premature ventricular contraction\",\n",
    "    \"Fusion of ventricular and normal beat\",\n",
    "    \"Unclassifiable beat\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de clases\n",
    "\n",
    "Veamos la distribución de las clases en el conjunto de datos para comprender mejor el problema de clasificación que estamos abordando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = df.iloc[:, -1].value_counts()\n",
    "print(class_count)\n",
    "\n",
    "class_count.sort_index().plot(kind=\"bar\", title=\"Número de muestras por clase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, las clases están desbalanceadas, lo que puede afectar el rendimiento de nuestro modelo. Por lo tanto, es importante tener en cuenta este desbalance al evaluar el rendimiento del modelo y considerar estrategias como el uso de pesos de clase o técnicas de aumento de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets y Dataloaders\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Vamos a crear un `Dataset` personalizado para cargar y preprocesar los datos del MIT-BIH Arrhythmia Database. Este `Dataset` se encargará de cargar los datos desde nuestros dataframe de Pandas, aplicar transformaciones, y devolver los datos en el formato adecuado para ser procesados por nuestros modelos de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MITBIHDataSet(Dataset):\n",
    "    def __init__(self, df_features, df_target, num_classes):\n",
    "        self.x_df = df_features.values\n",
    "        self.y_df = df_target.values\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.x_df[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y_df[idx], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split de datos\n",
    "\n",
    "Vamos a dividir nuestro conjunto de datos en conjuntos de entrenamiento y validacion. Esta vez en vez de hacerlo con [torch.utils.data.random_split](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) lo haremos con [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) para poder mantener el balance de clases en ambos conjuntos.\n",
    "\n",
    "> Por lo que pudimos observar en la exploración de datos, el conjunto de prueba ya tiene un balance de clases similar al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=SEED, stratify=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar la frecuencia de cada clase en cada conjunto\n",
    "class_counts_train = y_train.value_counts()\n",
    "class_counts_val = y_val.value_counts()\n",
    "\n",
    "# Crear subplots para los histogramas\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Histograma para train\n",
    "axes[0].bar(class_counts_train.index, class_counts_train.values, color=\"skyblue\")\n",
    "axes[0].set_title(\"Distribución de Clases en trian\")\n",
    "axes[0].set_xlabel(\"Clases\")\n",
    "axes[0].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "# Histograma para val\n",
    "axes[1].bar(class_counts_val.index, class_counts_val.values, color=\"lightgreen\")\n",
    "axes[1].set_title(\"Distribución de Clases en val\")\n",
    "axes[1].set_xlabel(\"Clases\")\n",
    "axes[1].set_ylabel(\"Frecuencia\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MITBIHDataSet(X_train, y_train, nclasses)\n",
    "val_dataset = MITBIHDataSet(X_val, y_val, nclasses)\n",
    "test_dataset = MITBIHDataSet(X_test, y_test, nclasses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders\n",
    "\n",
    "Definimos los dataloaders para cada conjunto de datos, estos son los que se encargan de cargar los datos en lotes durante el entrenamiento y la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(batch_size):\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = get_data_loaders(\n",
    "    BATCH_SIZE\n",
    ")  # obtenemos los dataloaders\n",
    "\n",
    "# probamos un batch del DataLoader\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(x_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de modelo\n",
    "\n",
    "Empezaremos definiendo un modelo de clasificación simple en PyTorch. Este modelo constará de dos capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP                                      [2048, 5]\n",
    "# ├─Linear: 1-1                            [2048, 512]\n",
    "# ├─Linear: 1-2                            [2048, 2048]\n",
    "# ├─Linear: 1-3                            [2048, 5]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, nclass):\n",
    "        super(MLP, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        return x\n",
    "\n",
    "summary(MLP(ninputs, nclasses), input_size=(BATCH_SIZE, ninputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, data_loader, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo en los datos proporcionados y calcula la pérdida promedio.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo que se va a evaluar.\n",
    "        criterion (torch.nn.Module): La función de pérdida que se utilizará para calcular la pérdida.\n",
    "        data_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de evaluación.\n",
    "\n",
    "    Returns:\n",
    "        float: La pérdida promedio en el conjunto de datos de evaluación.\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()  # ponemos el modelo en modo de evaluacion\n",
    "    total_loss = 0 # acumulador de la perdida\n",
    "    with torch.no_grad(): # deshabilitamos el calculo de gradientes\n",
    "        for x, y in data_loader: # iteramos sobre el dataloader\n",
    "            x = x.to(DEVICE) # movemos los datos al dispositivo\n",
    "            y = y.to(DEVICE) # movemos los datos al dispositivo\n",
    "            output = model(x) # forward pass\n",
    "            total_loss += criterion(output, y).item() # acumulamos la perdida\n",
    "    return total_loss / len(data_loader) # retornamos la perdida promedio\n",
    "\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device=DEVICE,\n",
    "    epochs=10,\n",
    "    log_fn=None,\n",
    "    log_every=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena el modelo utilizando el optimizador y la función de pérdida proporcionados.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo que se va a entrenar.\n",
    "        optimizer (torch.optim.Optimizer): El optimizador que se utilizará para actualizar los pesos del modelo.\n",
    "        criterion (torch.nn.Module): La función de pérdida que se utilizará para calcular la pérdida.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de entrenamiento.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de validación.\n",
    "        epochs (int): Número de épocas de entrenamiento (default: 10).\n",
    "        log_fn (function): Función que se llamará después de cada log_every épocas con los argumentos (epoch, train_loss, val_loss) (default: None).\n",
    "        log_every (int): Número de épocas entre cada llamada a log_fn (default: 1).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float]]: Una tupla con dos listas, la primera con el error de entrenamiento de cada época y la segunda con el error de validación de cada época.\n",
    "\n",
    "    \"\"\"\n",
    "    epoch_train_errors = []  # colectamos el error de traing para posterior analisis\n",
    "    epoch_val_errors = []  # colectamos el error de validacion para posterior analisis\n",
    "\n",
    "    for epoch in range(epochs): # loop de entrenamiento\n",
    "        model.train()  # ponemos el modelo en modo de entrenamiento\n",
    "        train_loss = 0 # acumulador de la perdida de entrenamiento\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device) # movemos los datos al dispositivo\n",
    "            y = y.to(device) # movemos los datos al dispositivo\n",
    "\n",
    "            optimizer.zero_grad() # reseteamos los gradientes\n",
    "\n",
    "            output = model(x) # forward pass (prediccion)\n",
    "            batch_loss = criterion(output, y) # calculamos la perdida con la salida esperada\n",
    "\n",
    "            batch_loss.backward() # backpropagation\n",
    "            optimizer.step() # actualizamos los pesos\n",
    "\n",
    "            train_loss += batch_loss.item() # acumulamos la perdida\n",
    "\n",
    "        train_loss /= len(train_loader) # calculamos la perdida promedio de la epoca\n",
    "        epoch_train_errors.append(train_loss) # guardamos la perdida de entrenamiento\n",
    "        val_loss = evaluate(model, criterion, val_loader) # evaluamos el modelo en el conjunto de validacion\n",
    "        epoch_val_errors.append(val_loss) # guardamos la perdida de validacion\n",
    "\n",
    "        if log_fn is not None: # si se pasa una funcion de log\n",
    "            if (epoch + 1) % log_every == 0: # loggeamos cada log_every epocas\n",
    "                log_fn(epoch, train_loss, val_loss) # llamamos a la funcion de log\n",
    "\n",
    "    return epoch_train_errors, epoch_val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01\n",
    "CRITERION = nn.CrossEntropyLoss().to(DEVICE)\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_log(epoch, train_loss, val_loss):\n",
    "    print(\n",
    "        f\"Epoch: {epoch + 1:03d}/{EPOCHS:03d} | Train Loss: {train_loss:.5f} | Val Loss: {val_loss:.5f}\"\n",
    "    )\n",
    "\n",
    "base_model = MLP(ninputs, nclasses).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(base_model.parameters(), lr=LR)\n",
    "\n",
    "epoch_train_errors, epoch_val_errors = train(\n",
    "    base_model,\n",
    "    optimizer,\n",
    "    CRITERION,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    DEVICE,\n",
    "    EPOCHS,\n",
    "    print_log,\n",
    "    5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss durante el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos los errores de entrenamiento y validación\n",
    "plot_taining(epoch_train_errors, epoch_val_errors)\n",
    "# graficamos los errores de entrenamiento y validación a partir de la época 5\n",
    "plot_taining(epoch_train_errors[5:], epoch_val_errors[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Vamos a evaluar el rendimiento de nuestro modelo en el conjunto de prueba utilizando métricas como la precisión, el recall y la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_classification_report(model, dataloader):\n",
    "    # Evaluación del modelo\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pass # TODO\n",
    "\n",
    "    # Calcular precisión (accuracy)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    # Reporte de clasificación\n",
    "    report = classification_report(\n",
    "        all_labels, all_preds, target_names=TARGET_NAMES\n",
    "    )\n",
    "    print(\"Reporte de clasificación:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_report(base_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas por Clase**\n",
    "- **Precision:** De lo que predije como esta clase, ¿cuánto acerté? (↑ = menos falsos positivos)\n",
    "  - `Precision = TP / (TP + FP)`\n",
    "- **Recall:** De todos los casos reales, ¿cuántos detecté? (↑ = menos falsos negativos)  \n",
    "  - `Recall = TP / (TP + FN)`\n",
    "- **F1-Score:** Balance entre precision y recall (media armónica)\n",
    "  - `F1 = 2 * (Precision * Recall) / (Precision + Recall)`\n",
    "- **Support:** Cantidad de muestras reales de esa clase\n",
    "\n",
    "**Métricas Globales**\n",
    "- **Accuracy:** % total de aciertos `(TP + TN) / Total`\n",
    "- **Macro Avg:** Promedio simple (todas las clases pesan igual)\n",
    "- **Weighted Avg:** Promedio ponderado por support (refleja desbalance)\n",
    "\n",
    "**Interpretación Rápida**\n",
    "- Valores → 1.0 = Mejor | Valores → 0.0 = Peor\n",
    "- Precision > Recall = Modelo conservador\n",
    "- Recall > Precision = Modelo agresivo  \n",
    "- Macro < Weighted = Mejor en clases mayoritarias\n",
    "- Support desigual = Dataset desbalanceado\n",
    "\n",
    "> **Donde:** TP = True Positives, FP = False Positives, FN = False Negatives, TN = True Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "1. **Implementar dropout**: Agregar más capas lineales al modelo y aplicar dropout después de cada capa. Evaluar el impacto de dropout en el rendimiento del modelo.\n",
    "\n",
    "2. **Implementar early stopping**: Implementar la técnica de early stopping para detener el entrenamiento cuando el rendimiento del modelo deja de mejorar en el conjunto de validación. Evaluar el impacto de early stopping en el rendimiento del modelo.\n",
    "\n",
    "3. **Implementar label smoothing**: Implementar la técnica de label smoothing para mejorar la generalización del modelo. Evaluar el impacto de label smoothing en el rendimiento del modelo.\n",
    "\n",
    "4. **Modelo libre**: Implementar un modelo de clasificación en PyTorch utilizando el MIT-BIH Arrhythmia Database. Experimentar con diferentes arquitecturas de modelos, hiperparámetros y técnicas de regularización para mejorar el rendimiento del modelo.\n",
    "\n",
    "5. **Comparación de modelos**: Con cuál de los modelos te quedarías si: \n",
    "    - Tuvieras que elegir el modelo con mejor precisión en promedio.\n",
    "    - Tuvieras que elegir el modelo con mejor recall en promedio.\n",
    "    - Tuvieras que elegir el modelo con mejor F1-score en promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejericio 1: Implementar dropout\n",
    "\n",
    "[Dropout](https://jmlr.org/papers/v15/srivastava14a.html) es una técnica de regularización utilizada en redes neuronales para prevenir el sobreajuste (overfitting). Consiste en desactivar aleatoriamente un subconjunto de neuronas durante el entrenamiento en cada paso de propagación hacia adelante. Esto ayuda a la red a no depender demasiado de ninguna neurona en particular, promoviendo una representación más robusta y generalizable de los datos.\n",
    "\n",
    "**¿Cómo Funciona Dropout?**\n",
    "\n",
    "Durante el entrenamiento, Dropout:\n",
    "1. **Apagado Aleatorio de Neuronas**: Un porcentaje de neuronas se apaga aleatoriamente en cada iteración.\n",
    "2. **Escalado de Neuronas Activas**: Las activaciones de las neuronas restantes se escalan para mantener el equilibrio en la red.\n",
    "\n",
    "**Evaluación y Dropout**\n",
    "\n",
    "Durante la evaluación, es crucial que las capas Dropout se comporten de manera diferente:\n",
    "- **Entrenamiento (`model.train()`)**: Dropout está activo, apagando neuronas y escalando las activaciones.\n",
    "- **Evaluación (`model.eval()`)**: Dropout está desactivado, permitiendo que todas las neuronas estén activas sin escalado de activaciones. Esto asegura que el modelo utilice toda su capacidad para hacer predicciones.\n",
    "\n",
    "**Implementación de Dropout en PyTorch**\n",
    "\n",
    "En PyTorch, podemos implementar Dropout utilizando la capa [`torch.nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html). Esta capa apaga aleatoriamente un porcentaje de neuronas durante el entrenamiento y escala las activaciones durante la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_torch = torch.rand((2,5)) # genero datos al azar\n",
    "print(rand_torch) # imprimimos sus valores\n",
    "drop_layer = nn.Dropout(0.5) # creamos una capa de dropout con un 50% de apagar una neurona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_layer.train() # por defecto ya esta en train mode\n",
    "print(drop_layer(rand_torch)) # 1) apaga (pone en 0) con una probablidad p definida en la capa 2) pondera los valores restantes proporcionalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_layer.eval() # al ponerlo en eval no deberia surtir efecto al pasar por la capa\n",
    "print(drop_layer(rand_torch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas reglas prácticas para usar Dropout de manera efectiva:\n",
    "\n",
    "- **Ubicación: \"Después de Activación, Nunca en Output\"**\n",
    "```python\n",
    "x = F.relu(self.fc(x))\n",
    "x = self.dropout(x)  # ✅ Después de activación\n",
    "# ❌ NUNCA dropout en la capa final\n",
    "```\n",
    "\n",
    "- **Valores: \"20-50 Rule\"**\n",
    "```python\n",
    "dropout = nn.Dropout(0.5)    # Capas ocultas (default)\n",
    "dropout = nn.Dropout(0.2)    # CNNs, RNNs, entrada\n",
    "# Si dudas → usa 0.3\n",
    "```\n",
    "\n",
    "- **Train/Eval: \"Siempre Cambia Modo\"**\n",
    "```python\n",
    "model.train()   # Entrenamiento\n",
    "model.eval()    # ⚠️ CRÍTICO para inferencia\n",
    "```\n",
    "\n",
    "- **Cuándo Usar: \"Solo si Overfittea\"**\n",
    "```python\n",
    "# train_acc=99%, val_acc=85% → Agrega dropout\n",
    "# train_acc=80%, val_acc=78% → No necesitas\n",
    "# Empieza sin dropout, agrega si necesitas\n",
    "```\n",
    "\n",
    "- **Arquitectura: \"Más Profundo = Menos Dropout\"**\n",
    "```python\n",
    "# 2-3 capas:  p=0.5\n",
    "# 5-10 capas: p=0.2-0.3  \n",
    "# 10+ capas:  p=0.1 o nada\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_EJ1(nn.Module):\n",
    "    def __init__(self, input_size, nclass, dropout=0.5):\n",
    "        super(MLP_EJ1, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "summary(MLP_EJ1(ninputs, nclasses), input_size=(BATCH_SIZE, ninputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunas preguntas para pensar:\n",
    "- ¿Por qué dropout no tiene parametros entrenables?\n",
    "- ¿Qué pasaría si no ponemos el modelo en eval mode durante la evaluación?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej1_model = MLP_EJ1(ninputs, nclasses, 0.2).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(ej1_model.parameters(), lr=LR)\n",
    "\n",
    "epoch_train_errors, epoch_val_errors = train(\n",
    "    ej1_model,\n",
    "    optimizer,\n",
    "    CRITERION,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    DEVICE,\n",
    "    EPOCHS,\n",
    "    print_log,\n",
    "    5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos los errores de entrenamiento y validación\n",
    "plot_taining(epoch_train_errors, epoch_val_errors)\n",
    "# graficamos los errores de entrenamiento y validación a partir de la época 5\n",
    "plot_taining(epoch_train_errors[5:], epoch_val_errors[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_report(ej1_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ¿Cómo se compara el resultado con el modelo sin dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura Adicional\n",
    "- [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://jmlr.org/papers/v15/srivastava14a.html) - Paper original de Dropout\n",
    "- [Deep Learning Book - Regularization](https://www.deeplearningbook.org/contents/regularization.html)\n",
    "- [Dive into Deep Learning - Dropout](https://d2l.ai/chapter_multilayer-perceptrons/dropout.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Implementar early stopping\n",
    "\n",
    "[Early stopping](https://en.wikipedia.org/wiki/Early_stopping) es una técnica de regularización utilizada para prevenir el sobreajuste en modelos de aprendizaje profundo. Consiste en detener el entrenamiento del modelo cuando el rendimiento en el conjunto de validación deja de mejorar, evitando así que el modelo se ajuste demasiado a los datos de entrenamiento.\n",
    "\n",
    "**¿Cómo Funciona Early Stopping?**\n",
    "\n",
    "Early stopping se basa en el principio de que, a medida que el modelo se entrena, el rendimiento en el conjunto de validación debería mejorar hasta cierto punto y luego comenzar a empeorar. Esto se debe a que el modelo se ajusta cada vez más a los datos de entrenamiento, lo que puede llevar a un sobreajuste. Early stopping busca detener el entrenamiento en el punto óptimo, antes de que el modelo comience a sobreajustarse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Cuántas épocas esperar después de la última mejora.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra clase `EarlyStopping` implementa la lógica de early stopping muy sencilla. Guarda la mejor loss de validación vista hasta el momento y detiene el entrenamiento si la loss de validación no mejora después de un cierto número de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo ponemos a prueba con un ejemplo sencillo\n",
    "early_stopping = EarlyStopping(patience=2)\n",
    "loss_simulated = [0.1, 0.09, 0.08, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]\n",
    "\n",
    "for i, loss in enumerate(loss_simulated):\n",
    "    early_stopping(loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\n",
    "            f\"Detener entrenamiento en la época {i + 1}, la mejor pérdida fue {early_stopping.best_score}\"\n",
    "        )\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a redefinir nuestro training loop para incluir la lógica de early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_es(\n",
    "    model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    patience=5,\n",
    "    epochs=10,\n",
    "    log_fn=None,\n",
    "    log_every=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Entrena el modelo utilizando el optimizador y la función de pérdida proporcionados.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo que se va a entrenar.\n",
    "        optimizer (torch.optim.Optimizer): El optimizador que se utilizará para actualizar los pesos del modelo.\n",
    "        criterion (torch.nn.Module): La función de pérdida que se utilizará para calcular la pérdida.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de entrenamiento.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de validación.\n",
    "        device (str): El dispositivo donde se ejecutará el entrenamiento.\n",
    "        patience (int): Número de épocas a esperar después de la última mejora en val_loss antes de detener el entrenamiento (default: 5).\n",
    "        epochs (int): Número de épocas de entrenamiento (default: 10).\n",
    "        log_fn (function): Función que se llamará después de cada log_every épocas con los argumentos (epoch, train_loss, val_loss) (default: None).\n",
    "        log_every (int): Número de épocas entre cada llamada a log_fn (default: 1).\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float]]: Una tupla con dos listas, la primera con el error de entrenamiento de cada época y la segunda con el error de validación de cada época.\n",
    "\n",
    "    \"\"\"\n",
    "    pass # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej2_model = MLP(ninputs, nclasses).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(ej2_model.parameters(), lr=LR)\n",
    "\n",
    "epoch_train_errors, epoch_val_errors = train_es(\n",
    "    ej2_model,\n",
    "    optimizer,\n",
    "    CRITERION,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    DEVICE,\n",
    "    3,\n",
    "    EPOCHS,\n",
    "    print_log,\n",
    "    5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficamos los errores de entrenamiento y validación\n",
    "plot_taining(epoch_train_errors, epoch_val_errors)\n",
    "# graficamos los errores de entrenamiento y validación a partir de la época 5\n",
    "plot_taining(epoch_train_errors[5:], epoch_val_errors[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_report(ej2_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lectura Adicional\n",
    "- \"Other than the obvious difference with the previous study (this used real data), it is\n",
    "important to note another significant point: in this case. we stopped iterating (by anyone\n",
    "particular criterion) when that criterion was leading to no new test set performance\n",
    "improvement\" - From: [Generalization and Parameter Estimation in Feedforward Nets: Some Experiments](https://proceedings.neurips.cc/paper/1989/file/63923f49e5241343aa7acb6a06a751e7-Paper.pdf)\n",
    "- [Deep Learning Book - Regularization](https://www.deeplearningbook.org/contents/regularization.html)\n",
    "- [Dive into Deep Learning - Early Stopping](https://d2l.ai/chapter_multilayer-perceptrons/generalization-deep.html#early-stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Implementar label smoothing\n",
    "\n",
    "[Label smoothing](https://towardsdatascience.com/what-is-label-smoothing-108debd7ef06) es una técnica de regularización utilizada en el entrenamiento de modelos de clasificación para mejorar la generalización y evitar que el modelo se vuelva demasiado confiado en sus predicciones. Consiste en suavizar las etiquetas de clase, en lugar de asignar una probabilidad de 1 a la clase correcta y 0 a las demás, se asigna una probabilidad ligeramente menor a la clase correcta y una probabilidad ligeramente mayor a las demás clases.\n",
    "\n",
    "Se pude aplicar con la siguiente formula:\n",
    "\n",
    "$$ y_{ls} = (1 - \\alpha) \\cdot y_{hot} + \\frac{\\alpha}{K} $$\n",
    "\n",
    "donde:\n",
    "- $y_{ls}$ son las etiquetas suavizadas.\n",
    "- $y_{hot}$ son las etiquetas originales en formato one-hot.\n",
    "- $\\alpha$ es el factor de suavizado (entre 0 y 1).\n",
    "- $K$ es el número de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de etiquetas (índices de clase)\n",
    "z = torch.tensor([0, 1, 2, 1, 3, 2])  # Etiquetas de ejemplo\n",
    "print(f\"Etiquetas\\n{z}\")\n",
    "\n",
    "# Convertir a one-hot encoding\n",
    "z_one_hot = F.one_hot(z, nclasses)\n",
    "print(f\"\\nOne-hot encoding\\n{z_one_hot}\")\n",
    "\n",
    "# Parámetro de suavizado\n",
    "alpha = 0.1  # Factor de suavizado\n",
    "K = nclasses\n",
    "\n",
    "# Aplicar label smoothing\n",
    "z_ls = (1 - alpha) * z_one_hot + alpha / K\n",
    "print(f\"\\nLabel smoothing\\n{z_ls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afortunadamente, PyTorch proporciona una implementación de label smoothing en la función de pérdida [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) a través del parámetro `label_smoothing`. Al establecer `label_smoothing` en un valor mayor que cero, se aplica label smoothing a la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej3_model = MLP(ninputs, nclasses).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(ej3_model.parameters(), lr=LR)\n",
    "\n",
    "epoch_train_errors, epoch_val_errors = train(\n",
    "    ej3_model,\n",
    "    optimizer,\n",
    "    criterion,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    DEVICE,\n",
    "    EPOCHS,\n",
    "    print_log,\n",
    "    5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_report(ej3_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
